# Valence Principles

These are non-negotiable. They define what Valence is and constrain what it can become. Any proposal that violates these principles requires extraordinary justification and broad consensus to even discuss.

## 1. Privacy by Default

Your beliefs are yours. Period.

- Beliefs are private unless explicitly shared by their owner
- No bulk surveillance of the belief graph
- Sharing is granular: you choose what to share, with whom, under what conditions
- The system must not infer private beliefs from public activity patterns
- "Default private" means exactly that — not "private unless you forget to toggle a setting"

**Test:** Can a new user add beliefs without any of them being visible to anyone else? If not, the system is broken.

## 2. Reputation from Rigor

Credibility comes from the quality of your reasoning, not the size of your audience.

- Reputation scores reflect accuracy, calibration, and intellectual honesty
- Popularity, volume, and social proof are not inputs to reputation
- A single well-sourced, carefully reasoned belief outweighs a thousand confident assertions
- Reputation is domain-specific — expertise in one area doesn't transfer automatically
- Gaming reputation (sockpuppets, coordinated amplification) is treated as a system integrity threat

**Test:** Can a new participant with zero followers establish credibility purely through accurate, well-reasoned contributions? If not, the incentives are wrong.

## 3. Exit Rights

You can always leave, and you can take your data with you.

- Full data export in standard, documented formats at any time
- No lock-in through proprietary data formats or network effects that trap data
- Leaving does not destroy your contribution history (but you can request anonymization)
- Third-party tools can build on the export format without permission
- Exit should be a single action, not a bureaucratic process

**Test:** Can a user export everything, delete their account, and import into a competing system? If not, we've built a roach motel.

## 4. No Central Censor

No single entity — including the Valence org — can unilaterally silence participants or suppress beliefs.

- Content moderation happens through trust networks, not central authority
- You control your own filters; the system doesn't decide what you can see
- Disputes are resolved through transparent processes, not executive fiat
- Even the core team is subject to governance processes, not above them
- There is a difference between "I don't trust this" and "nobody should see this" — the system supports the former, not the latter

**Test:** Can the Valence org suppress a belief that criticizes Valence? If yes, the architecture is wrong.

## 5. Transparency

The system's behavior must be understandable and auditable.

- Algorithms that affect belief visibility, reputation, or trust are open source
- Governance decisions are documented with rationale
- Changes to core systems go through public review
- Users can understand why they see what they see
- "Trust us" is never an acceptable answer to "how does this work?"

**Test:** Can an outsider read the code and governance docs and understand how decisions get made? If not, we're not transparent — we're just saying we are.

---

## Tensions and Tradeoffs

These principles sometimes conflict. Privacy and transparency pull in opposite directions. Exit rights and network integrity can clash. When they do:

1. Name the tension explicitly
2. Prefer the principle that protects individual agency
3. Document the tradeoff and the reasoning
4. Revisit as the system evolves

Perfection isn't the goal. Honest navigation of hard tradeoffs is.
